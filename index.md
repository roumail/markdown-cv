---
title: Rohail Taimour
---

<link rel="stylesheet" type="text/css" href="styles.css">
<img style="float:right" src="data/closeup-Photo.jpeg">

# Rohail Taimour
Python/R Software Engineer | Contract Data Scientist | Statistician | AI/Machine Learning Specialist
1040, Brussels, Belgium

<div id="webaddress">
rohail.taimour@gmail.com | +32 489 83 64 76
| <a href="https://www.linkedin.com/in/rohailtaimour/">Linkedin</a>
| <a href="https://github.com/roumail">Github</a>
</div>

## Summary

Experienced data scientist with an expertise in working on data products that have a machine learning focus. I am able to play a dynamic role between data scientist/machine learning engineer and data engineer given the needs of the project. I am passionate about adopting development best practices wherever possible and am comfortable working in an ambiguous and fast changing environment, laser focused on delivering user requirements in an agile manner.

## Education


<div class="edu-entry">
  <div class="education-entry">
    <div>MSc in Statistics</div>
    <div>KU Leuven, Leuven, Belgium</div>
    <div>2014-2016</div>
  </div>
  <ul class="edu-comments">
    <li>Gradted Cum Laude, Master’s thesis on continuous optimization of production processes in <strong>MATLAB</strong></li>
    <li>Treasurer for University Adventure Society organizing hiking trips for groups of upto 300 people in North of Pakistan</li>
  </ul>
</div>


<div class="edu-entry">
  <div class="education-entry">
    <div>BSc (Hons.) in Accounting and Finance</div>
    <div>Lahore University of Management Sciences (LUMS), Lahore, Pakistan</div>
    <div>2010-2014</div>
  </div>
  <ul class="edu-comments">
    <li>Graduated with Distinction (3.6/4.0)</li>
    <li>Courses: Operations Research, Supply Chain, Decision analysis, Applied Probability </li>
  </ul>
</div>

## Personal details

*  __Nationality__: Belgian, Pakistani
*  __Languages__: English (fluent/bilingual), Urdu (Native), French (B1)
*  __Mobility__: Driving Licence available, flexible for hybrid setup with up to 4 days on site  
*  __Availability__: Immediately
* __Hobbies__: Drumming and percussion instruments, Bouldering/Climbing, productivity, Squash, reading

## Technology stack and competencies

<table border="0">
  <tr>
    <td><h3>Development environment</h3></td>
    <td><h3>Machine Learning models</h3></td>
  </tr>
  <tr>
    <td>
      <ul>
        <li>Preferred python packages: pandas, pymc3, kedro, scikit-learn, sktime, seaborn, pytest, click, typer</li>
        <li>OS: Windows, MacOS, Linux (Redhat/Ubuntu)</li>
        <li>IDE: Pycharm, VScode, Rstudio, jupyter notebooks, Azure databricks</li>
        <li>Virtualization and Containerization Tools: Docker</li>
        <li>Code quality: black, pre-commit, isort, typing, flake8, mypy</li>
        <li>Version Control and CI/CD Tools: Git, GitHub/Azure Pipelines, GitHub CLI tools and Git flow branching</li>
        <li>Cloud platforms: AWS (S3, EC2), Azure (Blob, Databricks, Pipelines)</li>
        <li>Python Packaging: conda, mamba, pip, poetry</li>
        <li>Databases: Postgresql, SQLite3, Neo4j, sqlalchemy</li>
        <li>Documentation and Web Development Tools: Pandoc, Markdown, sphinx, CSS, HTML</li> 
        <li>MLflow for experiment tracking, model and artifact management, serving predictions</li>
      </ul>
    </td>
    <td>
      <ul>
        <li>Regression, classification, clustering using classical statistical methods</li>
        <li>Machine learning approaches (tree-based methods such as XGboost, Random Forest etc) on tabular data</li>
        <li>Time series forecasting, clustering, aggregation using bary centers</li>
        <li>Probabilistic programming, Monte Carlo simulation and Bayesian statistics</li>
        <li>Natural language processing (NLP) text embeddings, Named entity Recognition (NER), sentiment/topic analysis</li>
      </ul>
    </td>
  </tr>
</table>

<div style="page-break-after: always;"></div>

<table border="0">
  <tr>
    <td><h3>Soft skills</h3></td>
    <td><h3>Certifications</h3></td>
  </tr>
  <tr>
    <td>
      <ul>
        <li>Driven, proactive, dynamic, can-do attitude</li>
        <li>Diverse educational/work experience: accounting and finance, supply chain, statistics, data science</li>
        <li>Quick study for different business use cases, technology stacks, (machine learning) methods</li>
        <li>Strong communication skills and ability to deliver to deadlines</li>
        <li>Can work autonomously, as well as within a team</li>
        <li>Experienced in Agile rituals and breaking down complex requirements into achievable milestones</li>
      </ul>
    </td>
    <td>
      <ul>
        <li><strong>Python</strong>: 'Software engineering for Data scientists' (2019) from Ian Ozsvald (PyData London)</li>
        <li><strong>R</strong>: 'Advanced R Programming' (2014) from Belgian Open Source Analytical Consultants (BNOSAC)</li>
      </ul>
    </td>
  </tr>
</table>

## Freelance projects (Oct 2022-present) 

<div class="cv-entry">
  <h3 class="project-title">Development and Implementation of a Configurable Bioinformatics Pipeline for Event-Triggered Secondary Analysis of Sequencing Data Using Python and Docker</h3>
  <div class="table-without-border">
    <div class="table-row">
      <div class="table-cell">
        <p>Python Software Engineer & Data Pipeline Architect, Illumina, Mechelen, Belgium</p>
      </div>
      <div class="table-cell">
        <p>April 2023 - Present</p>
      </div>
    </div>
  </div>
  <ul class="project-details">
    <li><strong>Achievements:</strong>
      <ul>
        <li>Engineered a robust Python package, incorporating features such as advanced logging, exception handling, and automated testing, enhancing software reliability and maintainability.</li>
        <li>Implemented a <strong>Docker</strong>-based solution for the analysis process, facilitating seamless data exchange and enhancing the reproducibility and scalability.</li>
        <li>Developed a configurable multi-stage pipeline for secondary analysis, providing an intuitive user interface that abstracted the complexity of the underlying data pipeline.</li>
        <li>Designed and implemented an event-driven system that actively monitored for new sequencing data, triggering corresponding analyses upon detection of state changes, thereby ensuring timely and efficient processing of data.</li>
      </ul>
    </li>
    <li><strong>Responsibilities:</strong>
      <ul>
        <li>Provided guidance on automation strategies, leveraging CLI tools and API calls to enhance interoperability between Illumina platforms <strong>ICA</strong> and <strong>Basespace</strong>.</li>
        <li>Orchestrated the interaction between various services through <strong>ORM</strong> mapping, creating a simplified interface that abstracted the complexity of the underlying systems.</li>
        <li>Implemented unit testing using <strong>pytest</strong> and implemented fail-safe mechanisms for robust error handling.</li>
        <li>Optimized pipeline performance by implementing an <strong>SQLite</strong> database for tracking previously launched analyses, enabling the pipeline to function as a daemon with persistent memory.</li>
        <li>Produced comprehensive and accessible documentation using <strong>pandoc</strong> and <strong>markdown</strong>, facilitating understanding and usage of the pipeline across the organization.</li>
      </ul>
    </li>
  </ul>
</div>

<div class="cv-entry">
  <h3 class="project-title">Design and implement information retrieval methods using Natural language processing (NLP)</h3>
  <div class="table-without-border">
    <div class="table-row">
      <div class="table-cell">
        <p>Machine Learning Engineer, IT Supply Quality, GSK Belgium</p>
      </div>
      <div class="table-cell">
        <p>Oct 2022‑Feb 2023</p>
      </div>
    </div>
  </div>
  <ul class="project-details">
    <li><strong>Achievements:</strong>
      <ul>
        <li>Refactored and simplified python codebase, adding features such as better handling of non‑english emails, breaking emails into sentences, etc</li>
        <li>Improved performance of information retrieval by <strong>20%</strong> on unseen test data</li>
      </ul>
    </li>
    <li><strong>Responsibilities:</strong>
      <ul>
        <li>Defined and clarified KPI’s to track model performance evolution</li>
        <li>Implemented a text preprocessing pipeline in <strong> Azure Databricks </strong>using <strong>spacy</strong> tokenization, Part of speech (POS) tagging</li>
        <li>Performed POC’s on how to improve NLP model performance using rule based techniques as well as named entity recognition (<strong>NER</strong>)</li>
        <li>Annotated data to train a custom NER, storing model artifacts on <strong>Azure blob </strong></li>
      </ul>
    </li>
  </ul>
</div>


## Data science projects at IT AI team, UCB Pharmaceutical (2016‑Oct 2022)   

IT Artificial Intelligence (ITAI) is a global and cross functional team working across different use cases in the pharmaceutical industry from commercial (go to market), finance, manufacturing, to drug development and adverse event reporting. Our projects used a modern stack consisting of <strong>Docker</strong> as a consistent development environment, <strong>Amazon AWS</strong> for hosting analytic workflows, <strong>Microsoft Azure</strong> for CI/CD pipelines and git versioning.

<div class="cv-entry">
  <h3 class="project-title">Yield optimization for batch and continuous production processes using Machine Learning in Python</h3>
  <div class="table-without-border">
    <div class="table-row">
      <div class="table-cell">
        <p>Lead Data Scientist, Supply and Manufacturing, UCB Switzerland/Belgium</p>
      </div>
      <div class="table-cell">
        <p>Aug 2020‑Oct 2022</p>
      </div>
    </div>
  </div>
  <ul class="project-details">
    <li><strong>Achievements:</strong>
      <ul>
        <li>Supported delivery of workshops demystifying the process of conducting AI projects and machine learning to process experts</li>
        <li>Production setting proposed by model directly led to an <strong>increased throughput of 20%</strong>, turning in a <strong>recurring 1.5 million euro</strong> in annual cost savings</li>
      </ul>
    </li>
    <li><strong>Responsibilities:</strong>
      <ul>
        <li>Deliver a two-hour presentation weekly on insights from data, focusing on driving engagement and discussion within the process experts</li>
        <li>Deliver biweekly sprint review update on deliverables status</li>
        <li>Analyze time series data collected from equipment sensors and visually summarize golden batch insights</li>
        <li>Performed a thorough model validation and hyperparameter tuning exercise before recommending model insights be tested in a live production environment</li>
        <li>Created (bayesian) and tree-based regression models to quantify impact of process changes and predict batch performance</li>
        <li>Supporting the mentoring and training of junior data science profiles on the project</li>
      </ul>
    </li>
  </ul>
</div>


<div class="cv-entry">
  <h3 class="project-title">Optimize customer engagement based on promotional responsiveness by channel across EU5</h3>
  <div class="table-without-border">
    <div class="table-row">
      <div class="table-cell">
        <p>AI/ML engineer, Lead Data Scientist, Go to Market/Commerical EU5, US and Japan, UCB</p>
      </div>
      <div class="table-cell">
        <p>June 2019‑June 2021</p>
      </div>
    </div>
  </div>
  <ul class="project-details">
    <li><strong>Achievements:</strong>
      <ul>
        <li>Delivered as many as ten different use cases as lead data scientist for different products and countries</li>
        <li>Templated entire data science workflow into a configurable pipeline that could be executed for different countries/disease areas</li>
        <li>Created Python packages wrapping over <strong>scikit‑learn</strong> facilitating the training and tuning of models as well as data pre‑processing steps</li>
        <li>Supported reproducibility of analyses using <strong>MLflow </strong>that could allowed junior profiles to deliver higher quality, reproducible analyses</li>
      </ul>
    </li>
    <li><strong>Responsibilities:</strong>
      <ul>
        <li>Facilitate timeline and feasibility assessment for data science component together with the project manager</li>
        <li>Populate backlog with data science tasks during dailies and help prioritize to support timely deliveries</li>
        <li>Investigated adaptations to data science methodology for country/product specificities for maximum reusability</li>
        <li>Deliver biweekly sprint review update on deliverables status</li>
        <li>Validated ingested data using data visualization methods and discussions with subject matter experts</li>
        <li>Supported data engineers in the creation of features using <strong>pyspark</strong></li>
        <li>Created customer segmentation models and proposed optimal resource allocation based on customer responsiveness to different channels</li>
        <li>Developed a framework for logging model versions, data inputs, predictions and other model artifacts to a dashboard to facilitate discussion with the team and our stakeholders</li>
      </ul>
    </li>
  </ul>
</div>


<div class="cv-entry">
  <h3 class="project-title">Scientific influencer (KOLs) identification, ranking and profiling using network analytics and Neo4j</h3>
    <div class="table-without-border">
    <div class="table-row">
      <div class="table-cell">
        <p>Data scientist/Product owner, Drug Development, Commercial, Medical affairs, UCB</p>
      </div>
      <div class="table-cell">
        <p>2018‑2019</p>
      </div>
    </div>
  </div>
  <ul class="project-details">
    <li><strong>Achievements:</strong>
      <ul>
        <li>Successfully delivered 10+ KOL identification projects to stakeholders across the company</li>
        <li>Reduced time to deliver reports from days to hours by leading functional interface improvement with a senior software developer</li>
      </ul>
    </li>
    <li><strong>Responsibilities:</strong>
      <ul>
        <li>Introduce stakeholders to our product offering and understand their needs</li>
        <li>Prioritized request backlog, make request feasibility assessments for customisations and communicate timelines</li>
        <li>Define product roadmap to increase our capacity for taking in requests by improving the software foundations of our data product</li>
        <li>Create custom databases for each new request, ingesting additional data sources to quantify influence, as needed</li>
        <li>Provided customized KOL ranking/profiling reports and presentations based on stakeholder requirements</li>
        <li>Performed data quality checks by querying the database using <strong>Cypher</strong> from the Web UI as well as <strong>jupyter notebooks</strong></li>
        <li>Made network visualizations using <strong>networkx</strong>, Cytoscape and performed custom analysis</li>
      </ul>
    </li>
  </ul>
</div>

<div class="cv-entry">
  <h3 class="project-title">Developed an automated forecasting workflow of claims data from US healthcare system</h3>
  <div class="table-without-border">
    <div class="table-row">
      <div class="table-cell">
        <p>Lead Data Scientist, US Finance and claims, UCB</p>
      </div>
      <div class="table-cell">
        <p>2017‑2018</p>
      </div>
    </div>
  </div>
  <ul class="project-details">
    <li><strong>Achievements:</strong>
      <ul>
        <li>Created modular <strong>R packages</strong> to extend the functionality of Facebook's prophet package</li>
        <li>Created an end to end workflow for ingesting, forecasting and reporting with a user friendly interface to analyze forecasting results</li>
        <li>Achieved forecasting accuracy of <strong>> 90% </strong>across the different use cases</li>
      </ul>
    </li>
    <li><strong>Responsibilities:</strong>
      <ul>
        <li>Prototyped different time series forecasting methods to flexibly model multiple time series models</li>
        <li>Applied anomaly detection methods to account for outlying behavior in time series automatically</li>
        <li>Performed hyperparameter tuning and validation on a batch compute machine</li>
        <li>Created customized reports in <strong>Rmarkdown</strong> to show forecast metrics and visualization for each individual time series that was emailed to our stakeholders</li>
      </ul>
    </li>
  </ul>
</div>

<div class="cv-entry">
  <h3 class="project-title">Hands‑on workshop to demystify Artificial intelligence and Machine Learning</h3>
  <div class="table-without-border">
    <div class="table-row">
      <div class="table-cell">
        <p>Data science instructor, IT departments US, EU, UCB</p>
      </div>
      <div class="table-cell">
        <p>May‑ June 2017</p>
      </div>
    </div>
  </div>
  <ul class="project-details">
    <li><strong>Achievements:</strong>
      <ul>
        <li>Delivered the workshop to over <strong>100 people</strong> in four different venues and received great feedback on level of engagement</li>
        <li>Created a <strong>R shiny</strong> application to facilitate conducting the workshop, walking people through the typical AI use cases</li>
      </ul>
    </li>
    <li><strong>Responsibilities:</strong>
      <ul>
        <li>Prepare content for the workshop and decide on most engaging way to deliver the material</li>
        <li>Conduct the workshops, via hands on exercises on the content and debrief participants on solutions to the exercises</li>
      </ul>
    </li>
  </ul>
</div>

## Personal projects

* Developed webscraper in python (Beautiful soup, Selenium) to compare apartments based on price, area, etc   
* Created a predictive model for whether movie will achieve an imdb rating > 7.5 using best practices for data science projects


<!-- ### Footer Last updated: May 2013 -->


