---
title: Rohail Taimour
---

<link rel="stylesheet" type="text/css" href="styles.css">
<img style="float:right" src="data/closeup-Photo.jpeg">

# Rohail Taimour
Data Analyst | Statistician/Data Scientist | AI/Machine Learning expert  
1040, Brussels, Belgium

<div id="webaddress">
rohail.taimour@gmail.com | +32 489 83 64 76
| <a href="https://www.linkedin.com/in/rohailtaimour/">Linkedin</a>
| <a href="https://github.com/roumail">Github</a>
</div>

## Summary

Data analytics professional with 5+ years of experience in Digital Product Management, commercial optimization and data visualization work. I am able to contribute across the value chain of data products that have a machine learning focus. I am comfortable working in an ambiguous and fast changing environment, laser focused on delivering user requirements in an agile manner.

## Education


<div class="edu-entry">
  <div class="education-entry">
    <div>MSc in Statistics</div>
    <div>KU Leuven, Leuven, Belgium</div>
    <div>2014-2016</div>
  </div>
  <ul class="edu-comments">
    <li>Gradted Cum Laude, Master’s thesis on continuous optimization of production processes in <strong>MATLAB</strong></li>
    <li>Treasurer for University Adventure Society organizing hiking trips for groups of upto 300 people in North of Pakistan</li>
  </ul>
</div>


<div class="edu-entry">
  <div class="education-entry">
    <div>BSc (Hons.) in Accounting and Finance</div>
    <div>Lahore University of Management Sciences (LUMS), Lahore, Pakistan</div>
    <div>2010-2014</div>
  </div>
  <ul class="edu-comments">
    <li>Graduated with Distinction (3.6/4.0)</li>
    <li>Courses: Operations Research, Supply Chain, Decision analysis, Applied Probability </li>
  </ul>
</div>

## Personal details

*  __Nationality__: Belgian, Pakistani
*  __Languages__: English (fluent/bilingual), Urdu (Native), French (B1)
*  __Mobility__: Driving Licence available, flexible for hybrid setup with up to 4 days on site  
*  __Availability__: Immediately
* __Hobbies__: Drumming and percussion instruments, Bouldering/Climbing, productivity, Squash, reading

## Technology stack and competencies

<table border="0">
  <tr>
    <td><h3>Technical Skills</h3></td>
    <td><h3>Machine Learning models</h3></td>
  </tr>
  <tr>
    <td>
      <ul>
        <li>Visualization Tools: seaborn, plotly, bokeh, RShiny, networkx</li>
        <li>OS: Windows, MacOS, Linux (Redhat/Ubuntu)</li>
        <li>Database querying: SQL, Cypher</li>
      </ul>
    </td>
    <td>
      <ul>
        <li>Bayesian statistics for A/B testing and causal inference in small data sizes</li>
        <li>Regression, classification, clustering using classical statistical methods</li>
        <li>Machine learning approaches (tree-based methods such as XGboost, Random Forest etc) on tabular data</li>
        <li>Time series forecasting, clustering, aggregation using bary centers</li>
      </ul>
    </td>
  </tr>
  <tr>
    <td><h3>Soft skills</h3></td>
    <td><h3>Certifications</h3></td>
  </tr>
  <tr>
    <td>
      <ul>
        <li>Driven, proactive, dynamic, can-do attitude</li>
        <li>Diverse educational/work experience: accounting and finance, supply chain, statistics, data science</li>
        <li>Quick study for different business use cases, technology stacks, (machine learning) methods</li>
        <li>Strong communication skills and ability to deliver to deadlines</li>
        <li>Can work autonomously, as well as within a team</li>
        <li>Experienced in Agile rituals and breaking down complex requirements into achievable milestones</li>
      </ul>
    </td>
    <td>
      <ul>
        <li><strong>Python</strong>: 'Software engineering for Data scientists' (2019) from Ian Ozsvald (PyData London)</li>
        <li><strong>R</strong>: 'Advanced R Programming' (2014) from Belgian Open Source Analytical Consultants (BNOSAC)</li>
      </ul>
    </td>
  </tr>
</table>

## Freelance projects (Oct 2022-present) 

<div class="cv-entry">
  <h3 class="project-title">Analyse text data using Natural language processing (NLP) and create information extraction pipeline</h3>
  <div class="table-without-border">
    <div class="table-row">
      <div class="table-cell">
        <p>Machine Learning Engineer, IT Supply Quality, GSK Belgium</p>
      </div>
      <div class="table-cell">
        <p>Oct 2022‑Feb 2023</p>
      </div>
    </div>
  </div>
  <ul class="project-details">
    <li><strong>Achievements:</strong>
      <ul>
        <li>Refactored and simplified python codebase, adding features such as better handling of non‑english emails, breaking emails into sentences, etc</li>
        <li>Improved performance of information retrieval by <strong>20%</strong> on unseen test data</li>
      </ul>
    </li>
    <li><strong>Responsibilities:</strong>
      <ul>
        <li>Defined and clarified KPI’s to track model performance evolution</li>
        <li>Designed proof of concept (POC) to assess feasibility of implementing NLP model for business use case</li>
        <li>Implemented a text preprocessing pipeline in <strong> Azure Databricks </strong>using <strong>spacy</strong> tokenization, Part of speech (POS) tagging</li>
        <li>Sprint demo to business stakeholders to gain regular feedback</li>
      </ul>
    </li>
  </ul>
</div>


## Data science projects at IT AI team, UCB Pharmaceutical (2016‑Oct 2022)   

IT Artificial Intelligence (ITAI) is a global and cross functional team working across different use cases in the pharmaceutical industry from commercial (go to market), finance, manufacturing, to drug development and adverse event reporting. 

<div class="cv-entry">
  <h3 class="project-title">Analyse sensor data from batch and continuous production processes to optimize yield</h3>
  <div class="table-without-border">
    <div class="table-row">
      <div class="table-cell">
        <p>Supply and Manufacturing, UCB Switzerland/Belgium</p>
      </div>
      <div class="table-cell">
        <p>Aug 2020‑Oct 2022</p>
      </div>
    </div>
  </div>
  <ul class="project-details">
    <li><strong>Achievements:</strong>
      <ul>
        <li>Supported delivery of workshops demystifying the process of conducting AI projects and machine learning to process experts</li>
        <li>Production setting proposed by model directly led to an <strong>increased throughput of 20%</strong>, turning in a <strong>recurring 1.5 million euro</strong> in annual cost savings</li>
      </ul>
    </li>
    <li><strong>Responsibilities:</strong>
      <ul>
        <li>Query data from source systems using SQL via python</li>
        <li>Analyze time series data collected from equipment sensors and identify key trends for golden batch</li>
        <li>Proposed A/B testing experiments to evaluate the impact of different production settings on yield</li>
        <li>Created (bayesian) and tree-based regression models to analyse result of A/B tests</li>
        <li>Performed a thorough model validation and hyperparameter tuning exercise before recommending model insights be tested in a live production environment</li>
        <li>Deliver weekly presentation on insights from data, focusing on driving engagement and discussion within the process experts</li>
        <li>Deliver biweekly sprint review update on deliverables status</li>
        <li>Supporting the mentoring and training of junior data science profiles on the project</li>
      </ul>
    </li>
  </ul>
</div>


<div class="cv-entry">
  <h3 class="project-title">Optimize customer engagement based on promotional responsiveness by channel across EU5</h3>
  <div class="table-without-border">
    <div class="table-row">
      <div class="table-cell">
        <p>Go to Market/Commerical EU5, US and Japan, UCB</p>
      </div>
      <div class="table-cell">
        <p>June 2019‑June 2021</p>
      </div>
    </div>
  </div>
  <ul class="project-details">
    <li><strong>Achievements:</strong>
      <ul>
        <li>Delivered as many as ten different use cases as lead data scientist for different products and countries</li>
        <li>Analysed customer engagement data and created data visualizations to highlight high sales regions on an interactive map</li>
        <li>Create an automated pipeline to create a UI dashboard to faciliate discussion of model results using <strong>MLflow </strong></li>
      </ul>
    </li>
    <li><strong>Responsibilities:</strong>
      <ul>
        <li>Facilitate timeline and feasibility assessment for data science component together with the project manager</li>
        <li>Populate backlog with data science tasks during dailies and help prioritize to support timely deliveries</li>
        <li>Investigated adaptations to data science methodology for country/product specificities for maximum reusability</li>
        <li>Validated ingested data using data visualization methods and discussions with subject matter experts</li>
        <li>Created customer segmentation models and proposed optimal resource allocation based on customer responsiveness to different channels</li>
        <li>Deliver biweekly sprint review update on deliverables status</li>
      </ul>
    </li>
  </ul>
</div>


<div class="cv-entry">
  <h3 class="project-title">Create customized reports for scientific influencer (KOLs) identification, ranking and profiling using network analytics and Neo4j</h3>
    <div class="table-without-border">
    <div class="table-row">
      <div class="table-cell">
        <p>Drug Development, Commercial, Medical affairs, UCB</p>
      </div>
      <div class="table-cell">
        <p>2018‑2019</p>
      </div>
    </div>
  </div>
  <ul class="project-details">
    <li><strong>Achievements:</strong>
      <ul>
        <li>As a data analyst, successfully delivered 10+ KOL identification projects to stakeholders across the company</li>
        <li>As a product owner, reduced time to deliver reports from days to hours by leading functional interface improvement with a senior software developer</li>
      </ul>
    </li>
    <li><strong>Responsibilities:</strong>
      <ul>
        <li>Introduce stakeholders to our product offering and understand their needs</li>
        <li>Prioritized request backlog, make request feasibility assessments for customisations and communicate timelines</li>
        <li>Define product roadmap to increase our capacity for taking in requests by improving the software foundations of our data product</li>
        <li>Create custom databases for each new request, ingesting additional data sources to quantify influence, as needed</li>
        <li>Provided customized KOL ranking/profiling reports and presentations based on stakeholder requirements</li>
        <li>Performed data quality checks by querying the database using <strong>Cypher</strong> from the Web UI as well as <strong>jupyter notebooks</strong></li>
        <li>Made network visualizations using <strong>networkx</strong>, Cytoscape and performed custom analysis</li>
      </ul>
    </li>
  </ul>
</div>

<div class="cv-entry">
  <h3 class="project-title">Analyse US claims data and create customized reporting pipeline in R</h3>
  <div class="table-without-border">
    <div class="table-row">
      <div class="table-cell">
        <p>US Finance and claims, UCB</p>
      </div>
      <div class="table-cell">
        <p>2017‑2018</p>
      </div>
    </div>
  </div>
  <ul class="project-details">
    <li><strong>Achievements:</strong>
      <ul>
        <li>Created modular <strong>R packages</strong> to extend the functionality of Facebook's prophet package</li>
        <li>Created an end to end workflow for ingesting, forecasting and reporting with a user friendly interface to analyze forecasting results</li>
        <li>Achieved forecasting accuracy of <strong>> 90% </strong>across the different use cases</li>
      </ul>
    </li>
    <li><strong>Responsibilities:</strong>
      <ul>
        <li>Prototyped different time series forecasting methods to flexibly model multiple time series models</li>
        <li>Applied anomaly detection methods to account for outlying behavior in time series automatically</li>
        <li>Created customized reports in <strong>Rmarkdown</strong> to show forecast metrics and visualization for each individual time series that was emailed to our stakeholders</li>
      </ul>
    </li>
  </ul>
</div>

<div class="cv-entry">
  <h3 class="project-title">Created R Shiny application to support hands‑on workshop on demystifying Artificial intelligence and Machine Learning</h3>
  <div class="table-without-border">
    <div class="table-row">
      <div class="table-cell">
        <p>Data science instructor, IT departments US, EU, UCB</p>
      </div>
      <div class="table-cell">
        <p>May‑ June 2017</p>
      </div>
    </div>
  </div>
  <ul class="project-details">
    <li><strong>Achievements:</strong>
      <ul>
        <li>Delivered the workshop to over <strong>100 people</strong> in four different venues and received great feedback on level of engagement</li>
        <li>Created a <strong>R shiny</strong> application to facilitate conducting the workshop, walking people through the typical AI use cases</li>
      </ul>
    </li>
    <li><strong>Responsibilities:</strong>
      <ul>
        <li>Prepare content for the workshop and decide on most engaging way to deliver the material</li>
        <li>Conduct the workshops, via hands on exercises on the content and debrief participants on solutions to the exercises</li>
      </ul>
    </li>
  </ul>
</div>

## Personal projects

* Developed webscraper in python (Beautiful soup, Selenium) to compare apartments based on price, area, etc   
* Created a predictive model for whether movie will achieve an imdb rating > 7.5 using best practices for data science projects


